{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepspeed.utils.zero_to_fp32 import convert_zero_checkpoint_to_fp32_state_dict\n",
    "\n",
    "input_dir = './llama_ranker_model'\n",
    "tag = 'epoch_2'\n",
    "output_dir = './merged_model'\n",
    "convert_zero_checkpoint_to_fp32_state_dict(input_dir, output_dir, tag=tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import AutoConfig, AutoTokenizer\n",
    "from train_ranking_model_5_1b import RankingModel\n",
    "\n",
    "# 커스텀 RankingModel 인스턴스 생성\n",
    "model = RankingModel(\n",
    "    model_name='meta-llama/Llama-3.2-1B',\n",
    "    access_token='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',  # 실제 HuggingFace 토큰으로 변경\n",
    "    # num_layers_to_keep=16\n",
    ")\n",
    "\n",
    "\n",
    "# torch_model.bin 파일 경로\n",
    "state_dict_path = './merged_model/pytorch_model.bin'  # 실제 파일 경로로 수정\n",
    "\n",
    "# 상태 사전 로드\n",
    "state_dict = torch.load(state_dict_path, map_location=torch.device('cuda'))\n",
    "\n",
    "# 모델에 상태 사전 로드\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "# 저장 디렉토리 설정\n",
    "save_directory = './fine_tuned_llama_model'\n",
    "os.makedirs(save_directory, exist_ok=True)\n",
    "\n",
    "# 모델 저장\n",
    "model.save_pretrained(save_directory)\n",
    "\n",
    "# 토크나이저 로드 및 저장\n",
    "tokenizer = AutoTokenizer.from_pretrained('meta-llama/Llama-3.2-1B', use_auth_token='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')  # 실제 토큰으로 변경\n",
    "tokenizer.pad_token = tokenizer.eos_token  # EOS 토큰을 패딩 토큰으로 설정\n",
    "tokenizer.save_pretrained(save_directory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from train_ranking_model_5_1b import RankingModel \n",
    "import torch\n",
    "\n",
    "# 장치 설정: GPU가 사용 가능하면 GPU 사용, 그렇지 않으면 CPU 사용\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 모델과 토크나이저 로드\n",
    "model = RankingModel.from_pretrained(\n",
    "    'JinilPark/altari_ranker_model',\n",
    "    access_token='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'\n",
    ")\n",
    "# model = AutoModelForCausalLM.from_pretrained(\n",
    "#     'meta-llama/Llama-3.2-1B',\n",
    "#     token='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',\n",
    "#     torch_dtype=torch.float16\n",
    "# )\n",
    "    \n",
    "model.to(device)  # 모델을 장치로 이동\n",
    "model.eval()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    'JinilPark/altari_ranker_model',\n",
    "    token='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'\n",
    ")\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\n",
    "#     'meta-llama/Llama-3.2-1B',\n",
    "#     token='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',\n",
    "# )\n",
    "\n",
    "queries = [\n",
    "    \"What are the main causes of cataracts?\",\n",
    "    \"What are the main causes of cataracts?\",\n",
    "    \"What are the main causes of cataracts?\",\n",
    "    \"What are the main causes of cataracts?\",\n",
    "]\n",
    "docs = [    \n",
    "    \"Cataracts you're born with, called congenital cataracts. Some people are born with cataracts or develop them during childhood. These cataracts may be passed down from parents. They also may be associated with an infection or trauma while in the womb.\\nThese cataracts also may be due to certain conditions. These may include myotonic dystrophy, galactosemia, neurofibromatosis type 2 or rubella. Congenital cataracts don't always affect vision. If they do, they're usually removed soon after they're found.\\n\\n\\nRisk factorsFactors that increase your risk of cataracts include:\\n\\nIncreasing age.\\nDiabetes.\\nGetting too much sunlight.\\nSmoking.\\nObesity.\\nFamily history of cataracts.\\nPrevious eye injury or inflammation.\\nPrevious eye surgery.\\nProlonged use of corticosteroid medicines.\\nDrinking excessive amounts of alcohol.\\n\\nPreventionNo studies have proved how to prevent or slow the growth of cataracts. But health care professionals think several strategies may be helpful, including:\",\n",
    "    \"ReferencesMayo Clinic. Cataracts. https://www.mayoclinic.org/diseases-conditions/cataracts/symptoms-causes/syc-20353790. Accesed 5 Dec 2019.World Health Organization. Priority eye diseases. https://www.who.int/blindness/causes/priority/en/index1.html. Accesed 5 Dec 2019.Lou L, Ye X, Xu P, Wang J, Xu Y, Jin K, et al. Association of sex with the global burden of cataract. JAMA Ophthalmol. 2018;136:116–21. https://doi.org/10.1001/jamaophthalmol.2017.5668.Article \\n    PubMed \\n    \\n                    Google Scholar\",\n",
    "    \"CausesMost cataracts develop when aging or injury changes the tissue that makes up the eye's lens. Proteins and fibers in the lens begin to break down. This causes vision to become hazy or cloudy.\\nSome disorders passed down from parents that cause other health problems can increase your risk of cataracts. Cataracts also can be caused by other eye conditions, past eye surgery or medical conditions such as diabetes. Long-term use of steroid medicines also may cause cataracts to develop.\\nHow a cataract formsA cataract is a cloudy lens. The lens sits behind the colored part of your eye, called the iris. The lens focuses light that passes into your eye. This produces clear, sharp images on the back part of the eye, called the retina.\\nAs you age, the lenses in your eyes become less flexible, less clear and thicker. Aging and some medical conditions can cause proteins and fibers within the lenses to break down and clump together. This is what causes the clouding in the lenses.\\nAs the cataract grows, the clouding becomes worse. A cataract scatters and blocks the light as it passes through the lens. This prevents a sharply defined image from reaching your retina. As a result, your vision becomes blurred.\",\n",
    "    \"Cataracts you're born with, called congenital cataracts. Some people are born with cataracts or develop them during childhood. These cataracts may be passed down from parents. They also may be associated with an infection or trauma while in the womb.\\nThese cataracts also may be due to certain conditions. These may include myotonic dystrophy, galactosemia, neurofibromatosis type 2 or rubella. Congenital cataracts don't always affect vision. If they do, they're usually removed soon after they're found.\\n\\n\\nRisk factorsFactors that increase your risk of cataracts include:\\n\\nIncreasing age.\\nDiabetes.\\nGetting too much sunlight.\\nSmoking.\\nObesity.\\nFamily history of cataracts.\\nPrevious eye injury or inflammation.\\nPrevious eye surgery.\\nProlonged use of corticosteroid medicines.\\nDrinking excessive amounts of alcohol.\\n\\nPreventionNo studies have proved how to prevent or slow the growth of cataracts. But health care professionals think several strategies may be helpful, including:\",\n",
    "]\n",
    "\n",
    "for query, doc in zip(queries, docs):\n",
    "    # 쿼리와 문서를 토크나이즈하고 장치로 이동\n",
    "    inputs = tokenizer(query, return_tensors='pt').to(device)\n",
    "    doc_inputs = tokenizer(doc, return_tensors='pt').to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        scores = model(\n",
    "            query_input_ids=inputs['input_ids'],\n",
    "            query_attention_mask=inputs['attention_mask'],\n",
    "            doc_input_ids=doc_inputs['input_ids'],\n",
    "            doc_attention_mask=doc_inputs['attention_mask']\n",
    "        )\n",
    "        print(f\"Query: {query}\")\n",
    "        print(f\"Document: {doc}\")\n",
    "        print(f\"Score: {scores}\\n\")\n",
    "        \n",
    "if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 평가\n",
    "## nDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "import logging\n",
    "import json\n",
    "from train_ranking_model_5_1b import RankingDataset, RankingModel\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 로깅 설정\n",
    "logging.basicConfig(format='%(asctime)s - %(levelname)s - %(message)s', level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# 평가 데이터셋을 일부만 로드하는 함수\n",
    "def load_partial_dataset(data_file, max_samples=100):\n",
    "    \"\"\"\n",
    "    jsonl 파일에서 max_samples 개수만큼 데이터 로드\n",
    "    :param data_file: 데이터 파일 경로 (.jsonl 파일)\n",
    "    :param max_samples: 로드할 최대 샘플 개수\n",
    "    :return: 샘플 데이터 리스트\n",
    "    \"\"\"\n",
    "    samples = []\n",
    "    try:\n",
    "        with open(data_file, 'r', encoding='utf-8') as f:\n",
    "            for i, line in enumerate(f):\n",
    "                if i >= max_samples:\n",
    "                    break\n",
    "                sample = json.loads(line)\n",
    "                samples.append(sample)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to load dataset: {str(e)}\")\n",
    "        raise e\n",
    "    return samples\n",
    "\n",
    "# 평가 함수\n",
    "def evaluate_model(model, data_loader, k=10):\n",
    "    model.eval()  # 평가 모드로 전환\n",
    "    ndcg_scores = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader):\n",
    "            # 데이터를 GPU로 이동\n",
    "            batch = {k: v.cuda() for k, v in batch.items()}\n",
    "\n",
    "            # 쿼리와 긍정적/부정적 문서의 관련성 점수 계산\n",
    "            pos_scores = model(batch['query_input_ids'], batch['query_attention_mask'], batch['pos_input_ids'], batch['pos_attention_mask'])\n",
    "            neg_scores = model(batch['query_input_ids'], batch['query_attention_mask'], batch['neg_input_ids'], batch['neg_attention_mask'])\n",
    "            \n",
    "            # 관련성 레이블 (긍정: 1, 부정: 0)\n",
    "            scores = torch.cat([pos_scores, neg_scores], dim=0).cpu().numpy()\n",
    "            labels = np.array([1] * len(pos_scores) + [0] * len(neg_scores), dtype=np.float16)\n",
    "            labels = labels.reshape(1, -1)  # 2차원으로 변환\n",
    "            scores = scores.reshape(1, -1)  # 2차원으로 변환\n",
    "\n",
    "            # NDCG@k 계산\n",
    "            ndcg = ndcg_score_custom(labels, scores, k=k)\n",
    "            ndcg_scores.append(ndcg)\n",
    "\n",
    "    # NDCG 점수의 평균을 계산하여 반환\n",
    "    mean_ndcg = np.mean(ndcg_scores)\n",
    "    return mean_ndcg\n",
    "\n",
    "# NDCG 계산 함수\n",
    "def dcg_score(y_true, y_score, k=10):\n",
    "    order = np.argsort(y_score)[::-1]  # 예측 점수를 내림차순으로 정렬한 인덱스\n",
    "    y_true = np.take(y_true, order[:k])  # 상위 k개 항목의 실제 관련성 점수 추출\n",
    "    gain = 2 ** y_true - 1  # 이득(gain) 계산 (2^relevance - 1)\n",
    "    discounts = np.log2(np.arange(len(y_true)) + 2)  # 할인 요소 계산 (log2(rank + 1))\n",
    "    return np.sum(gain / discounts)\n",
    "\n",
    "def ndcg_score_custom(y_true, y_score, k=10):\n",
    "    best_dcg = dcg_score(y_true, y_true, k)  # 이상적인 DCG (관련성에 따라 정렬된 결과)\n",
    "    actual_dcg = dcg_score(y_true, y_score, k)  # 실제 DCG (예측 점수에 따라 정렬된 결과)\n",
    "    return actual_dcg / best_dcg if best_dcg > 0 else 0.0\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # 모델 불러오기\n",
    "    model = RankingModel.from_pretrained(\n",
    "        'JinilPark/altari_ranker_model',\n",
    "        access_token='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'\n",
    "    )\n",
    "    model.cuda()  # 모델을 GPU로 이동\n",
    "\n",
    "    model = torch.nn.DataParallel(model, device_ids=[0, 1, 2])  # GPU 0, 1, 2 사용\n",
    "    \n",
    "    \n",
    "    # 평가 데이터 준비\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        'JinilPark/altari_ranker_model',\n",
    "        token='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'\n",
    "    )\n",
    "\n",
    "    # jsonl 파일에서 일부 데이터 로드\n",
    "    max_samples = 100  # 평가에 사용할 샘플 수 설정\n",
    "    partial_samples = load_partial_dataset('./eval_ranker_dataset.jsonl', max_samples=max_samples)\n",
    "\n",
    "    # 데이터를 일부만 로드해서 Dataset 객체로 변환\n",
    "    eval_dataset = RankingDataset(data_file='./eval_ranker_dataset.jsonl', tokenizer=tokenizer)  # 기존 로드와의 호환을 위해 data_file=None\n",
    "    # eval_dataset.samples = partial_samples  # Dataset의 샘플을 부분 데이터로 대체\n",
    "\n",
    "    # 데이터 로더 생성\n",
    "    eval_loader = DataLoader(eval_dataset, batch_size=4, shuffle=False, num_workers=3)\n",
    "\n",
    "    # 평가 실행\n",
    "    try:\n",
    "        ndcg_score = evaluate_model(model, eval_loader, k=10)\n",
    "        logger.info(f\"NDCG@10: {ndcg_score:.4f}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Model evaluation failed: {str(e)}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
