{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 질문들"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "disease_questions=[\n",
    "    obesity_questions, \n",
    "    cataract_questions, \n",
    "    dementia_questions, \n",
    "    diabetes_questions,\n",
    "    rhinitis_questions,\n",
    "    gastritis_questions,\n",
    "    hair_loss_questions,\n",
    "    hemorrhoid_questions,\n",
    "    hypertension_questions,\n",
    "    hyperlipidemia_questions,\n",
    "    periodontal_disease_questions\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2200"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YAML 파일에서 리스트 불러오기\n",
    "import yaml\n",
    "path = 'c:/Users/USER/Desktop/GAS5_final_HSHCrew/AI/code/reranker/dataset/yaml/'\n",
    "diseases = [\n",
    "    'cataract', \n",
    "    'obesity', \n",
    "    'dementia', \n",
    "    'diabetes',\n",
    "    'rhinitis',\n",
    "    'gastritis',\n",
    "    'hair_loss',\n",
    "    'hemorrhoid',\n",
    "    'hypertension',\n",
    "    'periodontal_disease',\n",
    "    'hyperlipidemia',\n",
    "    ]\n",
    "diseases_questions = []\n",
    "for disease in diseases:\n",
    "    with open(path+f'{disease}_questions.yaml', 'r') as file:\n",
    "        loaded_questions = yaml.load(file, Loader=yaml.FullLoader)\n",
    "        diseases_questions+=loaded_questions\n",
    "len(diseases_questions)\n",
    "\n",
    "# 불러온 리스트 출력\n",
    "# print(loaded_questions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vectorDB 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vector_store = FAISS.load_local('c:/Users/USER/Desktop/GAS5_final_HSHCrew/AI/code/reranker/dataset/vectorDB', OpenAIEmbeddings(), allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import itertools\n",
    "import random\n",
    "from rank_bm25 import BM25Okapi\n",
    "# from sentence_transformers import SentenceTransformer, util\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "# 0. GPU 설정\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 1. 모델 로딩 (최적화 및 GPU 적용)\n",
    "# 전역 변수로 모델을 한 번만 로드합니다.\n",
    "bge_model = None\n",
    "bge_tokenizer = None\n",
    "cross_encoder_model = None\n",
    "cross_tokenizer = None\n",
    "\n",
    "def load_models(ranker_models):\n",
    "    \"\"\"\n",
    "    필요한 랭커 모델들을 로드하고 GPU로 이동합니다.\n",
    "    \"\"\"\n",
    "    global bge_model, bge_tokenizer, cross_encoder_model, cross_tokenizer\n",
    "\n",
    "    if 'BGE-Reranker' in ranker_models and bge_model is None:\n",
    "        bge_tokenizer = AutoTokenizer.from_pretrained('BAAI/bge-reranker-v2-m3')\n",
    "        bge_model = AutoModelForSequenceClassification.from_pretrained('BAAI/bge-reranker-v2-m3')\n",
    "        bge_model.to(device)\n",
    "\n",
    "    if 'Cross-Encoder' in ranker_models and cross_encoder_model is None:\n",
    "        cross_tokenizer = AutoTokenizer.from_pretrained('cross-encoder/ms-marco-MiniLM-L-6-v2')\n",
    "        cross_encoder_model = AutoModelForSequenceClassification.from_pretrained('cross-encoder/ms-marco-MiniLM-L-6-v2')\n",
    "        cross_encoder_model.to(device)\n",
    "\n",
    "# 2. 리랭커 모델로부터 점수 획득\n",
    "def get_ranker_scores(ranker_models, query, documents):\n",
    "    \"\"\"\n",
    "    각 리랭커 모델로부터 문서들에 대한 점수를 획득합니다.\n",
    "    \"\"\"\n",
    "    global bge_model, bge_tokenizer, cross_encoder_model, cross_tokenizer\n",
    "\n",
    "    ranker_scores = {model_name: {} for model_name in ranker_models}\n",
    "\n",
    "    # 쿼리와 문서 리스트 준비\n",
    "    doc_ids = list(documents.keys())\n",
    "    doc_texts = [documents[doc_id] for doc_id in doc_ids]\n",
    "\n",
    "    # 1. BM25 모델\n",
    "    if 'BM25' in ranker_models:\n",
    "        # 토큰화\n",
    "        tokenized_docs = [doc.split() for doc in doc_texts]\n",
    "        bm25 = BM25Okapi(tokenized_docs)\n",
    "        # 쿼리 토큰화\n",
    "        tokenized_query = query.split()\n",
    "        # 스코어 계산\n",
    "        scores = bm25.get_scores(tokenized_query)\n",
    "        # 결과 저장\n",
    "        for doc_id, score in zip(doc_ids, scores):\n",
    "            ranker_scores['BM25'][doc_id] = score\n",
    "\n",
    "    # 2. BGE-Reranker 모델\n",
    "    if 'BGE-Reranker' in ranker_models:\n",
    "        # 입력 생성 (GPU로 이동)\n",
    "        inputs = bge_tokenizer([query]*len(doc_texts), doc_texts, padding=True, truncation=True, return_tensors='pt').to(device)\n",
    "        # 모델 추론\n",
    "        with torch.no_grad():\n",
    "            outputs = bge_model(**inputs)\n",
    "            logits = outputs.logits\n",
    "            scores = logits.squeeze(-1)\n",
    "        # 결과 저장 (CPU로 이동하여 float로 변환)\n",
    "        for doc_id, score in zip(doc_ids, scores):\n",
    "            ranker_scores['BGE-Reranker'][doc_id] = score.item()\n",
    "\n",
    "    # 3. Cross-Encoder 모델\n",
    "    if 'Cross-Encoder' in ranker_models:\n",
    "        # 입력 생성 (GPU로 이동)\n",
    "        inputs = cross_tokenizer([query]*len(doc_texts), doc_texts, padding=True, truncation=True, return_tensors='pt').to(device)\n",
    "        # 모델 추론\n",
    "        with torch.no_grad():\n",
    "            outputs = cross_encoder_model(**inputs)\n",
    "            logits = outputs.logits\n",
    "            scores = logits.squeeze(-1)\n",
    "        # 결과 저장 (CPU로 이동하여 float로 변환)\n",
    "        for doc_id, score in zip(doc_ids, scores):\n",
    "            ranker_scores['Cross-Encoder'][doc_id] = score.item()\n",
    "\n",
    "    return ranker_scores\n",
    "\n",
    "# 이하 코드는 이전과 동일합니다.\n",
    "\n",
    "# 3. 각 리랭커 모델의 우열관계 도출\n",
    "def get_pairwise_preferences(ranker_scores):\n",
    "    \"\"\"\n",
    "    각 리랭커 모델별로 문서 쌍에 대한 우열관계를 도출합니다.\n",
    "    \"\"\"\n",
    "    pairwise_preferences = {model: [] for model in ranker_scores}\n",
    "    for model, scores in ranker_scores.items():\n",
    "        docs = list(scores.keys())\n",
    "        for doc_a, doc_b in itertools.combinations(docs, 2):\n",
    "            score_a = scores[doc_a]\n",
    "            score_b = scores[doc_b]\n",
    "            if score_a > score_b:\n",
    "                pairwise_preferences[model].append((doc_a, doc_b))  # doc_a가 승\n",
    "            elif score_a < score_b:\n",
    "                pairwise_preferences[model].append((doc_b, doc_a))  # doc_b가 승\n",
    "            else:\n",
    "                continue\n",
    "    return pairwise_preferences\n",
    "\n",
    "# 4. ELO Rating 계산\n",
    "def calculate_elo_ratings(documents, pairwise_preferences):\n",
    "    \"\"\"\n",
    "    모든 리랭커 모델의 우열관계를 합산하여 문서별 ELO 점수를 계산합니다.\n",
    "    \"\"\"\n",
    "    elo_ratings = {doc_id: 1500 for doc_id in documents}\n",
    "    K = 32\n",
    "    s = 400\n",
    "\n",
    "    all_preferences = []\n",
    "    for prefs in pairwise_preferences.values():\n",
    "        all_preferences.extend(prefs)\n",
    "\n",
    "    for doc_a, doc_b in all_preferences:\n",
    "        Ra = elo_ratings[doc_a]\n",
    "        Rb = elo_ratings[doc_b]\n",
    "        Ea = 1 / (1 + 10 ** ((Rb - Ra) / s))\n",
    "        Sa = 1\n",
    "        elo_ratings[doc_a] = Ra + K * (Sa - Ea)\n",
    "        elo_ratings[doc_b] = Rb + K * ((1 - Sa) - (1 - Ea))\n",
    "\n",
    "    return elo_ratings\n",
    "\n",
    "# 5. Adaptive Margin 계산\n",
    "def calculate_adaptive_margin(elo_ratings, s=400):\n",
    "    margins = {}\n",
    "    docs = list(elo_ratings.keys())\n",
    "    for doc_a, doc_b in itertools.combinations(docs, 2):\n",
    "        Ra = elo_ratings[doc_a]\n",
    "        Rb = elo_ratings[doc_b]\n",
    "        delta = abs(Ra - Rb)\n",
    "        P_ab = 1 / (1 + math.exp(-delta / s))\n",
    "        margin = 1 - P_ab\n",
    "        margins[(doc_a, doc_b)] = margin\n",
    "    return margins\n",
    "\n",
    "# 6. 트리플 생성\n",
    "def generate_training_triples(query, documents, elo_ratings, adaptive_margins):\n",
    "    triples = []\n",
    "    doc_ids = list(documents.keys())\n",
    "\n",
    "    for doc_a, doc_b in itertools.permutations(doc_ids, 2):\n",
    "        Ra = elo_ratings[doc_a]\n",
    "        Rb = elo_ratings[doc_b]\n",
    "        if Ra > Rb:\n",
    "            margin = adaptive_margins.get((doc_a, doc_b), 0.0)\n",
    "            triple = {\n",
    "                'query': query,\n",
    "                'positive_document': documents[doc_a],\n",
    "                'negative_document': documents[doc_b],\n",
    "                'margin': margin\n",
    "            }\n",
    "            triples.append(triple)\n",
    "    return triples\n",
    "\n",
    "# 7. 데이터셋 저장\n",
    "def save_dataset_for_llama(triples, filename='llama_ranker_dataset.jsonl'):\n",
    "    import json\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        for triple in triples:\n",
    "            json_line = json.dumps(triple, ensure_ascii=False)\n",
    "            f.write(json_line + '\\n')\n",
    "\n",
    "# 예시 실행\n",
    "if __name__ == \"__main__\":\n",
    "    # 여러 개의 쿼리 리스트\n",
    "    queries = diseases_questions  # obesity_questions는 쿼리의 리스트라고 가정합니다.\n",
    "\n",
    "    ranker_models = [\"BM25\", \"BGE-Reranker\", \"Cross-Encoder\"]\n",
    "\n",
    "    # 모델 로딩 (최적화 및 GPU 적용)\n",
    "    load_models(ranker_models)\n",
    "\n",
    "    # 전체 트리플을 저장할 리스트\n",
    "    all_triples = []\n",
    "\n",
    "    # 각 쿼리에 대해 처리\n",
    "    for query in tqdm(queries):\n",
    "        # 쿼리별로 문서들을 가져옴\n",
    "        retriever = vector_store.as_retriever(\n",
    "            search_kwargs={\n",
    "                'k': 3,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        docs = retriever.invoke(query)\n",
    "\n",
    "        # 문서들이 3개 미만인 경우 건너뜀\n",
    "        if len(docs) < 3:\n",
    "            print(f\"쿼리 '{query}'에 대한 문서가 3개 미만입니다. 건너뜁니다.\")\n",
    "            continue\n",
    "\n",
    "        documents = {\n",
    "            \"doc1\": docs[0].page_content,\n",
    "            \"doc2\": docs[1].page_content,\n",
    "            \"doc3\": docs[2].page_content,\n",
    "        }\n",
    "\n",
    "        # 1. 리랭커 모델로부터 점수 획득\n",
    "        ranker_scores = get_ranker_scores(ranker_models, query, documents)\n",
    "        # print(f\"\\n쿼리: {query}\")\n",
    "        # print(\"리랭커 모델 점수:\")\n",
    "        # for model, scores in ranker_scores.items():\n",
    "            # print(f\"{model}: {scores}\")\n",
    "\n",
    "        # 2. 각 리랭커 모델의 우열관계 도출\n",
    "        pairwise_preferences = get_pairwise_preferences(ranker_scores)\n",
    "        # print(\"\\n리랭커 모델별 우열관계:\")\n",
    "        # for model, prefs in pairwise_preferences.items():\n",
    "        #     print(f\"{model}: {prefs}\")\n",
    "\n",
    "        # 3. ELO Rating 계산\n",
    "        elo_ratings = calculate_elo_ratings(documents, pairwise_preferences)\n",
    "        print(\"\\nELO Ratings:\")\n",
    "        for doc_id, rating in elo_ratings.items():\n",
    "            print(f\"{doc_id}: {rating:.2f}\")\n",
    "\n",
    "        # 4. Adaptive Margin 계산\n",
    "        adaptive_margins = calculate_adaptive_margin(elo_ratings)\n",
    "        print(\"\\nAdaptive Margins:\")\n",
    "        for (doc_a, doc_b), margin in adaptive_margins.items():\n",
    "            print(f\"Margin({doc_a}, {doc_b}) = {margin:.4f}\")\n",
    "\n",
    "        # 5. 트리플 생성\n",
    "        triples = generate_training_triples(query, documents, elo_ratings, adaptive_margins)\n",
    "        print(\"\\n트레이닝 트리플:\")\n",
    "        for triple in triples:\n",
    "            print(triple)\n",
    "            all_triples.append(triple)  # 전체 트리플 리스트에 추가\n",
    "\n",
    "    # 6. 전체 데이터셋 저장\n",
    "    save_dataset_for_llama(all_triples)\n",
    "\n",
    "    print(\"\\n전체 데이터셋이 'llama_ranker_dataset.jsonl' 파일로 저장되었습니다.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
